{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Packages and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def get_points(file):\n",
    "    '''load matlab style file'''\n",
    "    mat = scipy.io.loadmat(file)\n",
    "    return mat[list(mat.keys())[3]]\n",
    "\n",
    "def pickle_save(filename, content):\n",
    "    '''save the file into python pickle object under output folder'''\n",
    "    with open('../output/%s.pkl'%filename, 'wb') as f:\n",
    "        pickle.dump(content, f)\n",
    "        \n",
    "def pickle_open(filename):\n",
    "    '''load the pickle file'''\n",
    "    with open('../output/%s.pkl'%filename, 'rb') as f:\n",
    "        content = pickle.load(f)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "### 1. Load data and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from pickle oject\n",
    "fiducial_pt_full = pickle_open('fiducial_pt_full')\n",
    "label_full = pickle_open('label_full')\n",
    "\n",
    "## Note: randomly split into training & test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(fiducial_pt_full, label_full, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train/test feature extraction\n",
    "\n",
    "Here, use pairwise distances as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost training feature extraction takes 0.633 seconds.\n",
      "XGBoost test feature extraction takes 0.146 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# extract pairwise distance as features (78*77/2=3003 features)\n",
    "# nrow=number of records of the dataset; ncol=3003\n",
    "start_time = time.time()\n",
    "feature_train = np.stack((pairwise_distances(X_train[i])[np.triu_indices(78, k = 1)] for i in range(X_train.shape[0])))\n",
    "print('XGBoost training feature extraction takes %s seconds.'%round((time.time()-start_time),3))\n",
    "\n",
    "start_time = time.time()\n",
    "feature_test = np.stack((pairwise_distances(X_test[i])[np.triu_indices(78, k = 1)] for i in range(X_test.shape[0])))\n",
    "print('XGBoost test feature extraction takes %s seconds.'%round((time.time()-start_time),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A balanced test data splitted from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_1 = y_test[y_test == 1]\n",
    "emotion_0 = y_test[y_test== 0]\n",
    "feature_1 = feature_test[y_test==1]\n",
    "feature_0 = feature_test[y_test==0]\n",
    "bal_feature = np.concatenate((feature_1[0:130],feature_0[0:130]),axis=0)\n",
    "bal_y = np.concatenate((emotion_1[0:130],emotion_0[0:130]),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train XGBoost model with training features and labels\n",
    "\n",
    "* scale_pos_weight = total_negative_examples / total_positive_examples\n",
    "* negative: majority; positive: minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 4.229\n"
     ]
    }
   ],
   "source": [
    "# majority is label 0; minority is label 1\n",
    "\n",
    "# estimate scale_pos_weight value\n",
    "estimate = np.sum(y_train==0)/np.sum(y_train==1)\n",
    "print('Estimate: %.3f' % estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgb(algo, X_train, y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=25):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = algo.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train.values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=xgb_param['n_estimators'], \n",
    "                          nfold=cv_folds,stratified=True, metrics='auc', \n",
    "                          early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
    "        algo.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    # fit the algorithm with cv selected parameters on training data\n",
    "    algo.fit(X_train, y_train, eval_metric='auc')\n",
    "    \n",
    "    # predict on training data\n",
    "    pred_train = algo.predict(X_train)\n",
    "    predprob_train = algo.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    # model report\n",
    "    print('\\nModel Report')\n",
    "    print('Accuracy (train): %.4f'%metrics.accuracy_score(y_train, pred_train))\n",
    "    print('AUC Score (train): %.4f'%metrics.roc_auc_score(y_train, predprob_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy (train): 1.0000\n",
      "AUC Score (train): 1.0000\n",
      "Training model takes 221.17 s\n"
     ]
    }
   ],
   "source": [
    "# use cross validation and early_stopping_rounds to decide n_estimators\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1500,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=4,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "time_start_xgb1 = time.time()\n",
    "\n",
    "fit_xgb(xgb1, feature_train, y_train)\n",
    "\n",
    "time_end_xgb1 = time.time()\n",
    "print('Training model takes {:.2f} s'.format(time_end_xgb1-time_start_xgb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set takes 0.0559 seconds\n",
      "Accuracy (test): 0.8300\n",
      "Precision (test): 0.7342\n",
      "Recall (test): 0.4173\n",
      "AUC Score (test): 0.8478\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pred_test = xgb1.predict(feature_test)\n",
    "predprob_test = xgb1.predict_proba(feature_test)[:,1]\n",
    "\n",
    "print('Predicting on test set takes %.4f seconds'%(time.time()-start_time))\n",
    "print('Accuracy (test): %.4f'%metrics.accuracy_score(y_test, pred_test))\n",
    "print('Precision (test): %.4f'%metrics.precision_score(y_test, pred_test))\n",
    "print('Recall (test): %.4f'%metrics.recall_score(y_test, pred_test))\n",
    "print('AUC Score (test): %.4f'%metrics.roc_auc_score(y_test, predprob_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 189,\n",
       " 'nthread': 4,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 4,\n",
       " 'seed': 27,\n",
       " 'subsample': 0.8,\n",
       " 'verbosity': 1}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check parameters\n",
    "xgb1.get_xgb_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Parameter tuning\n",
    "### 4.1 Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time cost 1115.06 s\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,8,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator = XGBClassifier(learning_rate=0.1, n_estimators=189, max_depth=5,\n",
    "                              min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                              objective= 'binary:logistic', nthread=4, scale_pos_weight=4, seed=27),\n",
    "    param_grid = param_test1, scoring='roc_auc',n_jobs=-1,cv=5)\n",
    "\n",
    "\n",
    "time_start_gs1 = time.time()\n",
    "\n",
    "gsearch1.fit(feature_train, y_train)\n",
    "\n",
    "time_end_gs1 = time.time()\n",
    "print('Tuning time cost {:.2f} s'.format(time_end_gs1-time_start_gs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.832756 using {'max_depth': 5, 'min_child_weight': 5}\n",
      "0.827208 (0.007249) with: {'max_depth': 3, 'min_child_weight': 1}\n",
      "0.823122 (0.007797) with: {'max_depth': 3, 'min_child_weight': 3}\n",
      "0.819270 (0.005282) with: {'max_depth': 3, 'min_child_weight': 5}\n",
      "0.830624 (0.005024) with: {'max_depth': 5, 'min_child_weight': 1}\n",
      "0.828628 (0.003036) with: {'max_depth': 5, 'min_child_weight': 3}\n",
      "0.832756 (0.007105) with: {'max_depth': 5, 'min_child_weight': 5}\n",
      "0.827725 (0.005165) with: {'max_depth': 7, 'min_child_weight': 1}\n",
      "0.822672 (0.004134) with: {'max_depth': 7, 'min_child_weight': 3}\n",
      "0.832728 (0.006745) with: {'max_depth': 7, 'min_child_weight': 5}\n"
     ]
    }
   ],
   "source": [
    "# report the best configuration\n",
    "print(\"Best: %f using %s\" % (gsearch1.best_score_, gsearch1.best_params_))\n",
    "\n",
    "# report all configurations\n",
    "means = gsearch1.cv_results_['mean_test_score']\n",
    "stds = gsearch1.cv_results_['std_test_score']\n",
    "params = gsearch1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Tune Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time cost 939.01 s\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "\n",
    "gsearch2 = GridSearchCV(\n",
    "    estimator = XGBClassifier(learning_rate=0.1, n_estimators=189, max_depth=5,\n",
    "                              min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                              objective= 'binary:logistic', nthread=4, scale_pos_weight=4, seed=27),\n",
    "    param_grid = param_test2, scoring='roc_auc',n_jobs=-1,cv=5)\n",
    "\n",
    "\n",
    "time_start_gs2 = time.time()\n",
    "\n",
    "gsearch2.fit(feature_train, y_train)\n",
    "\n",
    "time_end_gs2 = time.time()\n",
    "print('Tuning time cost {:.2f} s'.format(time_end_gs3-time_start_gs3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.833379 using {'gamma': 0.2}\n",
      "0.832756 (0.007105) with: {'gamma': 0.0}\n",
      "0.827531 (0.005324) with: {'gamma': 0.1}\n",
      "0.833379 (0.003730) with: {'gamma': 0.2}\n",
      "0.832165 (0.003866) with: {'gamma': 0.3}\n",
      "0.830586 (0.005902) with: {'gamma': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# report the best configuration\n",
    "print(\"Best: %f using %s\" % (gsearch2.best_score_, gsearch2.best_params_))\n",
    "\n",
    "# report all configurations\n",
    "means = gsearch2.cv_results_['mean_test_score']\n",
    "stds = gsearch2.cv_results_['std_test_score']\n",
    "params = gsearch2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tune regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time cost 1419.89 s\n"
     ]
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'reg_alpha':[0.005, 0.01, 0.05, 1],\n",
    " 'reg_lambda':[0.05, 0.1, 1]\n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(\n",
    "    estimator = XGBClassifier(learning_rate=0.1, n_estimators=189, max_depth=5,\n",
    "                              min_child_weight=5, gamma=0.2, subsample=0.8, colsample_bytree=0.8,\n",
    "                              objective= 'binary:logistic', nthread=4, scale_pos_weight=4, seed=27),\n",
    "    param_grid = param_test3, scoring='roc_auc',n_jobs=-1,cv=5)\n",
    "\n",
    "\n",
    "time_start_gs3 = time.time()\n",
    "\n",
    "gsearch3.fit(feature_train, y_train)\n",
    "\n",
    "time_end_gs3 = time.time()\n",
    "print('Tuning time cost {:.2f} s'.format(time_end_gs3-time_start_gs3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.832915 using {'reg_alpha': 1, 'reg_lambda': 1}\n",
      "0.824504 (0.004240) with: {'reg_alpha': 0.005, 'reg_lambda': 0.05}\n",
      "0.829220 (0.010068) with: {'reg_alpha': 0.005, 'reg_lambda': 0.1}\n",
      "0.832020 (0.007155) with: {'reg_alpha': 0.005, 'reg_lambda': 1}\n",
      "0.823307 (0.006179) with: {'reg_alpha': 0.01, 'reg_lambda': 0.05}\n",
      "0.826827 (0.004085) with: {'reg_alpha': 0.01, 'reg_lambda': 0.1}\n",
      "0.829055 (0.005793) with: {'reg_alpha': 0.01, 'reg_lambda': 1}\n",
      "0.831763 (0.014205) with: {'reg_alpha': 0.05, 'reg_lambda': 0.05}\n",
      "0.827051 (0.003367) with: {'reg_alpha': 0.05, 'reg_lambda': 0.1}\n",
      "0.828453 (0.006281) with: {'reg_alpha': 0.05, 'reg_lambda': 1}\n",
      "0.828249 (0.002748) with: {'reg_alpha': 1, 'reg_lambda': 0.05}\n",
      "0.828960 (0.002081) with: {'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "0.832915 (0.005444) with: {'reg_alpha': 1, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "# report the best configuration\n",
    "print(\"Best: %f using %s\" % (gsearch3.best_score_, gsearch3.best_params_))\n",
    "\n",
    "# report all configurations\n",
    "means = gsearch3.cv_results_['mean_test_score']\n",
    "stds = gsearch3.cv_results_['std_test_score']\n",
    "params = gsearch3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time cost 1985.69 s\n"
     ]
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'reg_alpha':[0.5, 1, 3, 5],\n",
    " 'reg_lambda':[0.5, 1, 3, 5]\n",
    "}\n",
    "\n",
    "gsearch4 = GridSearchCV(\n",
    "    estimator = XGBClassifier(learning_rate=0.1, n_estimators=189, max_depth=5,\n",
    "                              min_child_weight=5, gamma=0.2, subsample=0.8, colsample_bytree=0.8,\n",
    "                              objective= 'binary:logistic', nthread=4, scale_pos_weight=4, seed=27),\n",
    "    param_grid = param_test4, scoring='roc_auc',n_jobs=-1,cv=5)\n",
    "\n",
    "\n",
    "time_start_gs4 = time.time()\n",
    "\n",
    "gsearch4.fit(feature_train, y_train)\n",
    "\n",
    "time_end_gs4 = time.time()\n",
    "print('Tuning time cost {:.2f} s'.format(time_end_gs4-time_start_gs4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.833544 using {'reg_alpha': 1, 'reg_lambda': 5}\n",
      "0.831550 (0.003642) with: {'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "0.827960 (0.004573) with: {'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "0.824485 (0.005804) with: {'reg_alpha': 0.5, 'reg_lambda': 3}\n",
      "0.822690 (0.007957) with: {'reg_alpha': 0.5, 'reg_lambda': 5}\n",
      "0.831430 (0.001636) with: {'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "0.832915 (0.005444) with: {'reg_alpha': 1, 'reg_lambda': 1}\n",
      "0.832098 (0.005856) with: {'reg_alpha': 1, 'reg_lambda': 3}\n",
      "0.833544 (0.002235) with: {'reg_alpha': 1, 'reg_lambda': 5}\n",
      "0.825784 (0.004279) with: {'reg_alpha': 3, 'reg_lambda': 0.5}\n",
      "0.824243 (0.004478) with: {'reg_alpha': 3, 'reg_lambda': 1}\n",
      "0.826299 (0.006927) with: {'reg_alpha': 3, 'reg_lambda': 3}\n",
      "0.825894 (0.006178) with: {'reg_alpha': 3, 'reg_lambda': 5}\n",
      "0.827201 (0.002708) with: {'reg_alpha': 5, 'reg_lambda': 0.5}\n",
      "0.824550 (0.005536) with: {'reg_alpha': 5, 'reg_lambda': 1}\n",
      "0.829269 (0.004529) with: {'reg_alpha': 5, 'reg_lambda': 3}\n",
      "0.825618 (0.007652) with: {'reg_alpha': 5, 'reg_lambda': 5}\n"
     ]
    }
   ],
   "source": [
    "# report the best configuration\n",
    "print(\"Best: %f using %s\" % (gsearch4.best_score_, gsearch4.best_params_))\n",
    "\n",
    "# report all configurations\n",
    "means = gsearch4.cv_results_['mean_test_score']\n",
    "stds = gsearch4.cv_results_['std_test_score']\n",
    "params = gsearch4.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test): 0.8333\n",
      "AUC Score (test): 0.8403\n"
     ]
    }
   ],
   "source": [
    "pred_test = gsearch4.best_estimator_.predict(feature_test)\n",
    "predprob_test = gsearch4.best_estimator_.predict_proba(feature_test)[:,1]\n",
    "print('Accuracy (test): %.4f'%metrics.accuracy_score(y_test, pred_test))\n",
    "print('AUC Score (test): %.4f'%metrics.roc_auc_score(y_test, predprob_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy (train): 0.9988\n",
      "AUC Score (train): 1.0000\n",
      "Training mode takes 234.83 s\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=5,\n",
    " gamma=0.4,\n",
    " reg_alpha=1,\n",
    " reg_lambda=5,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=4,\n",
    " seed=27)\n",
    "\n",
    "time_start_xgb3 = time.time()\n",
    "\n",
    "fit_xgb(xgb3, feature_train, y_train)\n",
    "\n",
    "time_end_xgb3 = time.time()\n",
    "print('Training model takes {:.2f} s'.format(time_end_xgb3-time_start_xgb3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set takes 0.0555 seconds\n",
      "Accuracy (test): 0.8333\n",
      "Precision (test): 0.7097\n",
      "Recall (test): 0.4748\n",
      "AUC Score (test): 0.8342\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pred_test = xgb3.predict(feature_test)\n",
    "predprob_test = xgb3.predict_proba(feature_test)[:,1]\n",
    "\n",
    "print('Predicting on test set takes %.4f seconds'%(time.time()-start_time))\n",
    "print('Accuracy (test): %.4f'%metrics.accuracy_score(y_test, pred_test))\n",
    "print('Precision (test): %.4f'%metrics.precision_score(y_test, pred_test))\n",
    "print('Recall (test): %.4f'%metrics.recall_score(y_test, pred_test))\n",
    "print('AUC Score (test): %.4f'%metrics.roc_auc_score(y_test, predprob_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.4,\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=5, missing=None, n_estimators=194, n_jobs=1,\n",
       "              nthread=4, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=1, reg_lambda=5, scale_pos_weight=4, seed=27,\n",
       "              silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Tune weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time cost 1216.86 s\n"
     ]
    }
   ],
   "source": [
    "weights = [1, 5, 10, 20, 50, 70, 90, 100, 1000]\n",
    "param_grid = {'scale_pos_weight':weights}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "\n",
    "grid = GridSearchCV(estimator=xgb3, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "\n",
    "time_start_gs = time.time()\n",
    "\n",
    "grid_result = grid.fit(feature_train, y_train)\n",
    "\n",
    "time_end_gs = time.time()\n",
    "print('Tuning time cost {:.2f} s'.format(time_end_gs-time_start_gs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.841085 using {'scale_pos_weight': 10}\n",
      "0.840166 (0.017949) with: {'scale_pos_weight': 1}\n",
      "0.837953 (0.012144) with: {'scale_pos_weight': 5}\n",
      "0.841085 (0.011429) with: {'scale_pos_weight': 10}\n",
      "0.833068 (0.018257) with: {'scale_pos_weight': 20}\n",
      "0.819581 (0.013654) with: {'scale_pos_weight': 50}\n",
      "0.810718 (0.017646) with: {'scale_pos_weight': 70}\n",
      "0.811681 (0.016839) with: {'scale_pos_weight': 90}\n",
      "0.809549 (0.018111) with: {'scale_pos_weight': 100}\n",
      "0.771769 (0.023255) with: {'scale_pos_weight': 1000}\n"
     ]
    }
   ],
   "source": [
    "# report the best configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train): 0.9896\n",
      "AUC Score (train): 1.0000\n"
     ]
    }
   ],
   "source": [
    "pred_train = grid_result.best_estimator_.predict(feature_train)\n",
    "predprob_train = grid_result.best_estimator_.predict_proba(feature_train)[:,1]\n",
    "print('Accuracy (train): %.4f'%metrics.accuracy_score(y_train, pred_train))\n",
    "print('AUC Score (train): %.4f'%metrics.roc_auc_score(y_train, predprob_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (test): 0.8133\n",
      "Precision (test): 0.6031\n",
      "Recall (test): 0.5683\n",
      "AUC Score (test): 0.8318\n"
     ]
    }
   ],
   "source": [
    "pred_test = grid_result.best_estimator_.predict(feature_test)\n",
    "predprob_test = grid_result.best_estimator_.predict_proba(feature_test)[:,1]\n",
    "print('Accuracy (test): %.4f'%metrics.accuracy_score(y_test, pred_test))\n",
    "print('Precision (test): %.4f'%metrics.precision_score(y_test, pred_test))\n",
    "print('Recall (test): %.4f'%metrics.recall_score(y_test, pred_test))\n",
    "print('AUC Score (test): %.4f'%metrics.roc_auc_score(y_test, predprob_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.4,\n",
       "              learning_rate=0.05, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=5, missing=None, n_estimators=194, n_jobs=1,\n",
       "              nthread=4, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=1, reg_lambda=5, scale_pos_weight=10, seed=27,\n",
       "              silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[409,  52],\n",
       "       [ 60,  79]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After tuning, learning_rate=0.05, gamma=0.4, max_step=5, min_child_weight=5, n_estimators=194, reg_alpha=1, reg_lambda=5, scale_pos_weight=10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the trained model\n",
    "pickle_save('xgb_v1', grid_result.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_v1 = pickle_open('xgb_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "def clf_metrics(y_true, y_pred, y_score):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_score)\n",
    "    \n",
    "    df = pd.DataFrame({'accuracy':[accuracy],'precision': [precision], 'recall': [recall], 'auc':[auc]})\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "   accuracy  precision  recall  auc\n",
      "0  0.989583   0.948347     1.0  1.0\n",
      "\n",
      "\n",
      "Test set:\n",
      "   accuracy  precision    recall      auc\n",
      "0  0.813333   0.603053  0.568345  0.83177\n",
      "\n",
      "\n",
      "Balanced test set:\n",
      "   accuracy  precision    recall      auc\n",
      "0  0.753846   0.902439  0.569231  0.86503\n"
     ]
    }
   ],
   "source": [
    "# Tuned XGBoost performance\n",
    "pred_train = xgb_v1.predict(feature_train)\n",
    "score_train = xgb_v1.predict_proba(feature_train)[:,1]\n",
    "print('Training set:')\n",
    "clf_metrics(y_train, pred_train, score_train)\n",
    "print('\\n')\n",
    "\n",
    "pred_test = xgb_v1.predict(feature_test)\n",
    "score_test = xgb_v1.predict_proba(feature_test)[:,1]\n",
    "print('Test set:')\n",
    "clf_metrics(y_test, pred_test, score_test)\n",
    "print('\\n')\n",
    "\n",
    "pred_test = xgb_v1.predict(bal_feature)\n",
    "score_test = xgb_v1.predict_proba(bal_feature)[:,1]\n",
    "print('Balanced test set:')\n",
    "clf_metrics(bal_y, pred_test, score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
